\begin{abstract}
Satellite image restoration aims to improve image quality by compensating degradations (e.g., noise and blur) introduced by the imaging system and acquisition conditions. As a fundamental preprocessing step, restoration directly impacts both ground-based product generation and emerging onboard AI applications. Traditional restoration pipelines are based on sequential physical models computationally and memory demanding involving multiple operations and intermediate buffers, and poorly suited to resource constrained onboard environments.
We investigate whether a light and non-generative residual convolutional network (EDSR), trained exclusively on physics based simulated satellite data, can match or surpass a traditional ground-processing restoration pipeline across multiple operating conditions .\textit{/ while meeting the efficiency requirements of onboard deployment.} A realistic simulation framework modeling ground sampling distance (GSD), modulation transfer function (MTF), and signal dependent noise is used to generate supervised training pairs without relying on unavailable raw/L1 ground-truth data. By sampling degradations across a wide range of operating conditions, the model learns robustness to variability in blur and noise.
Experiments conducted on simulated datasets, real Pleiades imagery, and object detection tasks demonstrate that the proposed approach achieve competitive performance with respect to the traditional pipeline in image quality while significantly reducing end-to-end processing time. Physical indicators confirm robust blur compensation across varying degradation levels. Moreover, restoration consistently improves downstream detection performance, highlighting its relevance for onboard AI pipelines. Finally, we demonstrate its effective deployment on embedded hardware, validating its onboard applicability.

\end{abstract}

